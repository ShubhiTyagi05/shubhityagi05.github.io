<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script>
    <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.2/css/font-awesome.min.css">
    <link rel="stylesheet" href="../css/styles.css"> 
    <link rel="icon" type="image/png" href="../images/favicon.ico">
    <title>Shubhi Tyagi | Project Implementations</title>
</head>
<body>

    
<nav class="navbar navbar-default">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#collapsemenu">
                <span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span>
            </button>
            <a href="../index.html" class="navbar-brand">Shubhi Tyagi</a>
        </div>
        <div class="collapse navbar-collapse" id="collapsemenu">
            <ul class="nav navbar-nav navbar-right">
                <li class="active"><a href="#"><i class="fa fa-list-alt" aria-hidden="true"></i> Projects</a></li>
                <li><a href="../html/reviews.html"><i class="fa fa-language" aria-hidden="true"></i> Reviews</a></li>
                <li><a href="../html/hobbies.html"><i class="fa fa-heart"></i> Hobbies</a></li>
            </ul>
        </div>
    </div>
</nav>

<div class="container">
    <blockquote class="text-center">
        <p>"The best way to predict the future is to invent it”</p>
        <small>Alan Kay<cite title="Source Title">.</cite></small>
    </blockquote>
    <legend>A peek into some of my projects</legend>
    <div class="panel-group">
        <div class="panel panel-default">
            <div class="panel-heading">ATP Analytics</div>
            <div class="panel-body">
                <p> This was a project for Association Of Tennis Professionals (ATP) to generate powerful analytical insights from tennis matches. The objective was to analyse a players performance under various circumstances and thus predict his performance in a match based on the information obtained from the historical data. This was achieved by evaluating enhanced statistics for each kind of a particular shot played by a player against each opponent and basing the future predictions on the basis of these evaluated statistics.  
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">Entity Resolution for Big Data</div>
            <div class="panel-body">
                <p>Entity Resolution is the task of disambiguating manifestations of real world entities in various records or mentions by linking and grouping. For example, there could be different ways of addressing the same person in text, different addresses for businesses, or photos of a particular object. I solved this problem by establishing inference across networks and semantic relationships between entities. Created implementations for schema and data normalization, dictionary lookups for starters. Further reduced the complexity by proposing canonicalized references to particular entities and de-duplicating and linking entities.
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">Facial Key Points Detection</div>
            <div class="panel-body">
                <p>This is a little advanced implmentation of deep neural networks to detect key feature points on a human face. I implemented a convolutional neural network to learn to find the correct position of 15 facial key points like left eye center, right eye outer corner, mouth center bottom lip, etc. from a dataset of 7,049 96*96 gray-scale images. Then further enhanced the network performance by integrating pooling and dropout techniques.
                <br>
                Dataset Used      - Kaggle  data set (7049 images)
                <br>
                Achieved root mean squared error - 2.13.
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">Python</span>&nbsp;&nbsp;
                <span class="label label-primary">Theano</span>&nbsp;&nbsp;
                <span class="label label-primary">Lasagne</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">Handwritten Digit Recognition </div>
            <div class="panel-body">
                <p>This project was the first of my deep neural networks implementations. This neural network builds a Softmax Regresssion Model using the pixels of an image as its input layer and learns the appropriate weights and biases using Backpropogation Algorithm and Gradient Descent, thus predicting the digit as 0-9. It further uses the concepts of Convolution Layers and Pooling to improve the accuracy.
                <br>
                Dataset Used      - MNIST data set (70,000 images)
                <br>
                Accuracy Achieved - 99.2%
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">Python</span>&nbsp;&nbsp;
                <span class="label label-primary">TensorFlow</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">Movie Recommender System </div>
            <div class="panel-body">
                <p>This project uses collaborative and content-based filtering to learn the preferences of consumers with respect to the Movie industry. It uses a set of movie reviewers who have rated a list of movies and other metadata of a particular movie such as the genre, director, lead cast etc. as training set. It analyses the preferences of the test user and suggests him/her a list of movies they are most likely to like and a list of fellow users who have a taste similar to them. This project is based on the statistical analysis of the training data calculating the correlation between different reviewers and also between movies. Higher the correlation coefficient more likely it is for the users to like the movie or share similar tastes with other reviewers.
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
                <span class="label label-primary">Guava</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
         <div class="panel panel-default">
            <div class="panel-heading">Titanic – Machine Learning from Disaster (Kaggle)</div>
            <div class="panel-body">
                <p>This program builds a Logistic Regression Model along with Random Forest Classification to predict which passengers survived the tragedy using the structured data given as input. 
                <br>
                Accuracy Achieved - 82%
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
                <span class="label label-primary">Guava</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">Sentiment Analysis </div>
            <div class="panel-body">
                <p>This is yet another probabilistic predictive model based on Naïve Bayes Theorem which assigns a sentiment to the given case as one of the following – POSITIVE, NEGATIVE or NEUTRAL. It uses a training set of text data which have been assigned one of the above mentioned sentiments. This particular model uses Ngrams for a particular test instance as its feature vector and analyzes the collective probability for a particular sentiment of all the Ngrams with respect to all the Ngrams and their annotations from the test set.
                <br>
                Dataset Used      - Rotten Tomatoes Movie Reviews (10,662 reviews)
                <br>
                Accuracy Achieved - 80%
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
                <span class="label label-primary">Guava</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">Project Recommendation Engine</div>
            <div class="panel-body">
                <p>The objective of this project was to develop a recommendation engine from the data of a list of users and the respective projects associated with them. It recommends users a list of projects associated with other users which might be relevant to them by finding similarity between the projects using project details like expected outcome, clients, business objective etc. This implementation uses term frequency and inverse document frequency to analyze the degree of similarity between different projects and rank them in decreasing order of precedence.
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
                <span class="label label-primary">Guava</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading">LaTeX Parser and Analysis </div>
            <div class="panel-body">
                <p>Built a utility for an academic publishing company with the largest collection of science journals for structuring their 10 million LaTeX documents enabling it further for location specific search and retrieval within a document and analytics. Also provided a search engine on top of it.
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">GATE</span>&nbsp;&nbsp;
                <span class="label label-primary">JAPE</span>&nbsp;&nbsp;
                <span class="label label-primary">Apache SOLR</span>&nbsp;&nbsp;
                <span class="label label-primary">Java</span>
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading bold">Rich Text Format (RTF) Parser</div>
            <div class="panel-body">
                <p>The objective of this project was to build a parser for RTF documents from scratch for providing modules for reusability, searching and other forms of data analysis of unstructured data. It extracted sections from a given RTF document including the metadata. The biggest obstacle in this parser was to extract accurately complex tables which had multiple and irregular row spanning and column spanning. Further after data extraction Text Analytics was applied for auto-identification and annotation of useful entities in the text (like organization name, country, report name, etc.) using JAPE coding and GATE. After this the documents were indexed using Apache SOLR with priority boost given to specific extracted fields. Finally combining all of this a search engine was deployed to extract useful data wished by the user from a repository of a million documents and display the relevant statistics and data in decreasing order of precedence.  It is used by Underwriters Laboratories to extract and analyze their collection of data of over 100 years.
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">GATE</span>&nbsp;&nbsp;
                <span class="label label-primary">JAPE</span>&nbsp;&nbsp;
                <span class="label label-primary">Apache SOLR</span>&nbsp;&nbsp;
                <span class="label label-primary">Java</span>
            </div>
        </div>
        <br>
        <div class="panel panel-default">
            <div class="panel-heading bold">Spam Filter </div>
            <div class="panel-body">
                <p>This was my first machine learning based project which uses elementary techniques to differentiate a regular mail from a spam one. It is based on a Naïve Bayes Classifier which uses the training data which is a set of mails marked as regular or spam. Based on the content and the metadata of these mails a probabilistic model is created which assigns a probability to the use case given as a measure of whether the mail is spam or not. 
                </p>
            </div>
            <div class="panel-footer">
                <span class="label label-primary">JAVA</span>&nbsp;&nbsp;
                <span class="label label-primary">Guava</span>&nbsp;&nbsp;
            </div>
        </div>
        <br>
    </div>
</div>  
<footer class="text-center">
    <a type="button" href="https://in.linkedin.com/in/shubhityagi" target="_blank" class="btn btn-primary btn-circle"><i class="fa fa-linkedin" aria-hidden="true"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a type="button" href="https://www.hackerearth.com/@shubhi18" target="_blank" class="btn btn-primary btn-circle"><i class="fa fa-h-square" aria-hidden="true"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a type="button" href="https://twitter.com/shubhityagi05" target="_blank" class="btn btn-primary btn-circle"><i class="fa fa-twitter" aria-hidden="true"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a type="button" href="mailto:tyagi.shubhi@yahoo.com" class="btn btn-primary btn-circle"><i class="fa fa-envelope" aria-hidden="true"></i></a>&nbsp;&nbsp;&nbsp;&nbsp;
    <span>© Shubhi Tyagi 2016</span>
</footer>
    
</body>
</html>
